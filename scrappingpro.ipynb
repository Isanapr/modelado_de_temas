{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "scrappingpro.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "OCptk99nGBfO",
        "_ERx2Q4UGRcQ",
        "nGOw0RT-KGT5"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Web Scrapping**"
      ],
      "metadata": {
        "id": "p7VVTKCWUo1m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing modules"
      ],
      "metadata": {
        "id": "OCptk99nGBfO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install praw &> /dev/null\n",
        "!pip install scrubadub &> /dev/null #to autodetect the mail and phone numbers\n",
        "!pip install spacy &> /dev/null #to identify with NLP parts of the sentence\n",
        "!pip install tweepy &> /dev/null\n",
        "!apt-get update &> /dev/null\n",
        "!apt install chromium-chromedriver &> /dev/null\n",
        "%pip install selenium &> /dev/null\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin &> /dev/null"
      ],
      "metadata": {
        "id": "OjQhqpubCZPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Scrapper modules\n",
        "import praw #Reddit\n",
        "import tweepy #Twitter\n",
        "#Note: Youtube has special modules listed in its cell.\n",
        "\n",
        "#Filtering modules\n",
        "import re\n",
        "import spacy\n",
        "import scrubadub\n",
        "\n",
        "#Data modules\n",
        "import pandas as pd\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "Ydsy58gaTnPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filtering function"
      ],
      "metadata": {
        "id": "_ERx2Q4UGRcQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Filtering function\n",
        "\n",
        "model = spacy.load('en_core_web_sm') #loading the english NLP version\n",
        "model.tokenizer.rules = {key: value for key, value in model.tokenizer.rules.items() \n",
        "                        if \"'\" not in key and \"’\" not in key and \"‘\" not in key} #to avoid spacy splitting words with apostrophe\n",
        "\n",
        "def remove_emojis(text):\n",
        "    emoj = re.compile(\"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
        "        u\"\\U00002702-\\U000027B0\"\n",
        "        u\"\\U00002702-\\U000027B0\"\n",
        "        u\"\\U000024C2-\\U0001F251\"\n",
        "        u\"\\U0001f926-\\U0001f937\"\n",
        "        u\"\\U00010000-\\U0010ffff\"\n",
        "        u\"\\u2640-\\u2642\" \n",
        "        u\"\\u2600-\\u2B55\"\n",
        "        u\"\\u200d\"\n",
        "        u\"\\u23cf\"\n",
        "        u\"\\u23e9\"\n",
        "        u\"\\u231a\"\n",
        "        u\"\\ufe0f\"  # dingbats\n",
        "        u\"\\u3030\"\n",
        "                      \"]+\", re.UNICODE)\n",
        "    return re.sub(emoj, '', text)\n",
        "\n",
        "def filter(text, socialnet=\"\", GPE=True, PERSON=True):\n",
        "  \"\"\"\n",
        "  Filter that removes confidential data\n",
        "  params:\n",
        "    text(str): Text to filter.\n",
        "    socialnet(str): Removes username. \"twitter\" is supported.\n",
        "    GPE(bool): If True, removes Geographical locations.\n",
        "    GPE(bool): If True, removes personal names.\n",
        "  output:\n",
        "    filtstr(str): Filtered string.\n",
        "  \"\"\"\n",
        "  text=remove_emojis(text)\n",
        "  textspacy = model(text) \n",
        "  filtstr = ''\n",
        "  entities=['DATE']\n",
        "  if GPE:\n",
        "    entities.append(\"GPE\")\n",
        "  if PERSON:\n",
        "    entities.append(\"PERSON\")\n",
        "  for word in textspacy:\n",
        "      if word.ent_type_ in entities:\n",
        "          new_word = ''\n",
        "      elif word.pos_ == 'PUNCT':\n",
        "          new_word = word.text\n",
        "      else:\n",
        "          new_word = ' {}'.format(word.text)\n",
        "      filtstr += new_word\n",
        "\n",
        "  filtstr = filtstr[1:] #Avoiding the first space, all names, dates and locations deleted\n",
        "\n",
        "  scrubber = scrubadub.Scrubber(post_processor_list=[scrubadub.post_processors.FilthRemover(),]) #For removing {{EMAIL}}\n",
        "\n",
        "  filtstr = scrubber.clean(filtstr, replace_with='identifier') #Cleaning mails and phone numbers\n",
        "\n",
        "  #Cleaning urls: https://stackoverflow.com/questions/11331982/how-to-remove-any-url-within-a-string-in-python\n",
        "  regex_url=r'''(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’]))'''\n",
        "  filtstr=re.sub(regex_url,\"\",filtstr)\n",
        "\n",
        "  if socialnet==\"twitter\":\n",
        "    filtstr=re.sub(r\"\\@\\w+[,]|\\@\\w+|[,]\\@\\w+\",\"\",filtstr) #Deletes user\n",
        "\n",
        "  return(filtstr)\n"
      ],
      "metadata": {
        "id": "pH64AKf45tKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "re.sub(r\"\\@\\w+[,]|\\@\\w+|[,]\\@\\w+\",\"\", \"sus @amongus sus us\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "tPgqBWTTgtCe",
        "outputId": "b13cc928-2371-411e-9b4d-46eb9a2b41e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'sus  sus us'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Reddit API**"
      ],
      "metadata": {
        "id": "REvI3xjeGIV-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import praw\n",
        "\n",
        "# to use PRAW\n",
        "reddit = praw.Reddit(\n",
        "    client_id = \"wj8_QX85_EbUs2QDepC5Cg\",\n",
        "    client_secret = \"Z0jQjlUd9QQMXBfjN9dDKt8HKulCTg\",\n",
        "    username = \"xelastro\",\n",
        "    password = \"#aA5535241528\",\n",
        "    redirect_uri= \"http://localhost:8081\",\n",
        "    user_agent = \"second agent\"\n",
        ")\n",
        "\n",
        "#checking everything is ok\n",
        "\n",
        "print(reddit.user.me())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLw2yZMEcKa_",
        "outputId": "c04fa202-c342-47a4-b00b-46be2f89882b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "xelastro\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing Reddit user output"
      ],
      "metadata": {
        "id": "4GyYKgZTGo_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Potential edit, change the user you want to see comments from, avoid the /u, only place the username\n",
        "user = \"JohnnyLibRight\"\n",
        "\n",
        "\n",
        "ids = [] #to save the comment IDs\n",
        "#pattern = (r\"Comment/(id='(?P<id>.+)'/)\")\n",
        "\n",
        "for my_id in reddit.redditor(user).comments.new(limit=35): \n",
        "    \"\"\"\n",
        "    limit set as None can maximum retrieve 1000 comments due to Reddits cache \n",
        "    using limit as 35 for waiting less time\n",
        "    \"\"\"\n",
        "    my_id = str(my_id) #casting\n",
        "    ids.append(my_id) #generate your list with all comment IDs\n",
        "\n",
        "comment_cont = []\n",
        "\n",
        "for comment in ids:\n",
        "    \"\"\"\n",
        "    To generate a list with both the comment body and date\n",
        "    \"\"\"\n",
        "    commentObject = reddit.comment(comment) #Generating the comment object\n",
        "    comment_cont.append([commentObject.body, filter(commentObject.body), datetime.fromtimestamp(commentObject.created_utc)]) \n",
        "\n",
        "#Creating the dataframe\n",
        "data = pd.DataFrame(comment_cont, columns = ['Post', 'Filtered', 'Date'])\n",
        "filtered_posts = data[['Filtered']]\n",
        "print(filtered_posts)\n",
        "print(data.head(15))\n",
        "\n",
        "#Generating the full .csv\n",
        "path = user + '_Reddit.csv'\n",
        "data.to_csv(path)\n",
        "\n",
        "#Generating the .csv for only the filtered posts for topic modeling\n",
        "from google.colab import files\n",
        "path2 = user + '_Filtered_Reddit.csv'\n",
        "filtered_posts.to_csv(path2)\n",
        "files.download(path2)"
      ],
      "metadata": {
        "id": "L-sbjCKBcVbk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "505823af-b04e-40a7-9c53-f42cc32fde2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             Filtered\n",
            "0                                                 Mr.\n",
            "1                                                    \n",
            "2   The singer commented on a post detailing the s...\n",
            "3   The singer commented on a post detailing the s...\n",
            "4                         Ye vs The People underrated\n",
            "5    I could tell was the mind behind Seinfeld Wan...\n",
            "6    I could tell was the mind behind Seinfeld \\n ...\n",
            "7                                            Source: \n",
            "8                                                  or\n",
            "9   Let ’s get em the dirt cake It ’s his favorite...\n",
            "10                                       WestTaleEver\n",
            "11                           I found this from Edrick\n",
            "12  A state investigation launched after ’s killin...\n",
            "13  Rose was allowed to remain on the force for de...\n",
            "14  An assailant opened fire during a death metal ...\n",
            "15                                             YZY PF\n",
            "16                              Oh yeah? Watch this!-\n",
            "17  Nah this match was Sports Entertainment, And i...\n",
            "18               Where did these awards come from lol\n",
            "19  if you richer than can you just finish all gro...\n",
            "20  Twitter has accepted ’s offer to purchase the ...\n",
            "21                                      But Fed = Ded\n",
            "22  Isn’t this a reference to what happened in tha...\n",
            "23  aHR0cHM6Ly9vbmx5ZmlsZXMuaW8vZi8wMDY4OTczNGM3Mj...\n",
            "24  We respect all sexualities uce but have you co...\n",
            "25  I would buy anything with name on it. I’m a shill\n",
            "26  Exclusively at and the Super Smash Bros Soundt...\n",
            "27                                          thank you\n",
            "28         can you post the spotify link to the album\n",
            "29                          Ye a serial cheater and a\n",
            "30                                  Who tf is Problem\n",
            "31  Drake is also off key which is like the part w...\n",
            "32                                                   \n",
            "33                               yes that ’s the joke\n",
            "34  I mean digital nas and theo said there is a ve...\n",
            "                                                 Post  \\\n",
            "0                                        Mr. Miyagi 🙏   \n",
            "1   https://www.nypost.com/2020/07/03/elon-musk-de...   \n",
            "2   The singer commented on a post detailing the s...   \n",
            "3   The singer commented on a post detailing the s...   \n",
            "4                         Ye vs The People underrated   \n",
            "5   “I could tell Larry David was the mind behind ...   \n",
            "6   “I could tell Larry David was the mind behind ...   \n",
            "7   Source: https://www.latimes.com/entertainment-...   \n",
            "8                                    or Dan Schneider   \n",
            "9   Let’s get em the dirt cake It’s his favorite f...   \n",
            "10                                   WestTaleEver 😂😂😂   \n",
            "11                           I found this from Edrick   \n",
            "12  A state investigation launched after George Fl...   \n",
            "13  Rose was allowed to remain on the force for ye...   \n",
            "14  An assailant opened fire during a death metal ...   \n",
            "\n",
            "                                             Filtered                Date  \n",
            "0                                                 Mr. 2022-04-29 15:33:31  \n",
            "1                                                     2022-04-29 13:39:04  \n",
            "2   The singer commented on a post detailing the s... 2022-04-29 13:24:35  \n",
            "3   The singer commented on a post detailing the s... 2022-04-29 13:24:19  \n",
            "4                         Ye vs The People underrated 2022-04-29 12:44:25  \n",
            "5    I could tell was the mind behind Seinfeld Wan... 2022-04-29 05:34:43  \n",
            "6    I could tell was the mind behind Seinfeld \\n ... 2022-04-29 05:32:31  \n",
            "7                                            Source:  2022-04-28 18:30:40  \n",
            "8                                                  or 2022-04-28 18:20:08  \n",
            "9   Let ’s get em the dirt cake It ’s his favorite... 2022-04-28 18:04:34  \n",
            "10                                       WestTaleEver 2022-04-28 02:09:01  \n",
            "11                           I found this from Edrick 2022-04-28 01:55:40  \n",
            "12  A state investigation launched after ’s killin... 2022-04-27 16:08:24  \n",
            "13  Rose was allowed to remain on the force for de... 2022-04-27 15:58:40  \n",
            "14  An assailant opened fire during a death metal ... 2022-04-27 14:13:55  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_78f82ee6-45f5-4fe6-bbe5-9a7fa1e702d9\", \"JohnnyLibRight_Filtered_Reddit.csv\", 3325)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Twitter API**"
      ],
      "metadata": {
        "id": "GeceQwmCG0ih"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Twitter Api declaration"
      ],
      "metadata": {
        "id": "YYVjIckIKSSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Run the credentials\n",
        "import tweepy\n",
        "consumer_key=\"aSwakAUteSogeMh51A8U1j556\"\n",
        "consumer_secret=\"SBKzkHJpAOW1VReY8FhG1LSkacT67phFdfzP8jf5LEWgqv34Fk\"\n",
        "access_token=\"1311524883306696705-5lIgx9wKegu3zyYArkx8gaZPZdoHpt\"\n",
        "access_token_secret=\"SARjk6tC2va17NJPyYsWoAegqOvP0ugD0QmA1X0mdu1Yl\"\n",
        "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "api = tweepy.API(auth)"
      ],
      "metadata": {
        "id": "ZYes_iU8KNJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Twitter status by user:"
      ],
      "metadata": {
        "id": "Nd-bWcGfJ9IH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "userID = \"economics\"#<-----User without @ \n",
        "maxcount=5000 #<-------------Number of tweets \n",
        "\n",
        "#Twitter Api retrieves only a finite amount of tweets. \n",
        "#Therefor, here's a loop that retrieves the last tweet id per iteration.\n",
        "\n",
        "test_tweet = api.user_timeline(screen_name=userID, count=200, include_rts = False)\n",
        "maxid=test_tweet[0].id #latest maxid in timeline\n",
        "\n",
        "tweets=[]; parcial_tweets=[1]\n",
        "while len(tweets)<maxcount and len(parcial_tweets)!=0:\n",
        "  parcial_tweets = api.user_timeline(screen_name=userID, \n",
        "                            # 200 is the maximum allowed count. Without excluding replies and rts.\n",
        "                            count=200,\n",
        "                            include_rts = False,\n",
        "                            # Necessary to keep full_text \n",
        "                            # otherwise only the first 140 words are extracted\n",
        "                            exclude_replies=True,\n",
        "                            tweet_mode = 'extended',\n",
        "                            max_id=maxid\n",
        "                            )\n",
        "  if len(parcial_tweets)!=0:\n",
        "    maxid=parcial_tweets[-1].id\n",
        "  if len(tweets)!=0: #Non repeated tweets after first iter\n",
        "    parcial_tweets=parcial_tweets[1:]\n",
        "  tweets.extend(parcial_tweets)\n",
        "  print(f\"progress: {len(tweets)}\")\n",
        "if len(tweets)>maxcount:\n",
        "  tweets=tweets[0:maxcount]\n",
        "filename=userID\n",
        "print(\"Total tweets: \"+str(len(tweets)))"
      ],
      "metadata": {
        "id": "hPiumA5x3VCJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a5fb578-f875-4998-98bf-b17d0fbc03cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "progress: 150\n",
            "progress: 282\n",
            "progress: 408\n",
            "progress: 589\n",
            "progress: 728\n",
            "progress: 857\n",
            "progress: 1024\n",
            "progress: 1183\n",
            "progress: 1333\n",
            "progress: 1484\n",
            "progress: 1643\n",
            "progress: 1769\n",
            "progress: 1909\n",
            "progress: 2085\n",
            "progress: 2237\n",
            "progress: 2390\n",
            "progress: 2445\n",
            "progress: 2445\n",
            "Total tweets: 2445\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Twitter status by query"
      ],
      "metadata": {
        "id": "nGOw0RT-KGT5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query=\"Monterrey -filter:retweets\"\n",
        "#More info about twitter queries;\n",
        "#https://developer.twitter.com/en/docs/twitter-api/v1/rules-and-filtering/search-operators\n",
        "\n",
        "tweets=api.search(query, \n",
        "                  count=100,\n",
        "                  tweet_mode = 'extended')\n",
        "filename=\"Monterrey-tweets-100\""
      ],
      "metadata": {
        "id": "d4-G44xgd2I3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing Twitter user output: Filter and export"
      ],
      "metadata": {
        "id": "YVAwZS5rG516"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rows = []\n",
        "for info in tweets:\n",
        "     rows.append([info.full_text, filter(info.full_text, \"twitter\", False, False), info.created_at])\n",
        "\n",
        "df_twitter = pd.DataFrame(rows, columns=[\"Tweet\", \"Filtered\", \"Date\"])\n",
        "filtered_tweets = df_twitter[['Filtered']]\n",
        "print(df_twitter.head(10))\n",
        "\n",
        "#Generating the .csv\n",
        "path3 = filename + '_TW.csv'\n",
        "df_twitter.to_csv(path3)\n",
        "\n",
        "#Generating the .csv for only the filtered posts for topic modeling\n",
        "from google.colab import files\n",
        "path4 = filename + '_Filtered_TW.csv'\n",
        "filtered_tweets.to_csv(path4)\n",
        "files.download(path4)"
      ],
      "metadata": {
        "id": "-GUDAJqe3lgP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "f72da600-4d94-454d-cc75-638ab1bf81b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               Tweet  \\\n",
            "0  Waste-to-hydrogen technology firm Concord Blue...   \n",
            "1  Bitcoin is struggling to gain traction in El S...   \n",
            "2  The Star Ferry, an icon of Hong Kong and argua...   \n",
            "3  Food and energy price surges worsened by the U...   \n",
            "4  President Joe Biden is considering forgiving a...   \n",
            "5  Inflation, lingering supply chain disruptions ...   \n",
            "6  Few places in the U.S. have felt the sting of ...   \n",
            "7  Warren Buffett’s Berkshire Hathaway pulled bac...   \n",
            "8  The EU seeks a ban on Russian oil by the end o...   \n",
            "9  Mexico's fastest inflation in two decades may ...   \n",
            "\n",
            "                                            Filtered    Date of creation  \n",
            "0  Waste- to- hydrogen technology firm Concord Bl... 2022-04-30 18:29:21  \n",
            "1  Bitcoin is struggling to gain traction in El S... 2022-04-30 18:08:05  \n",
            "2  The Star Ferry, an icon of Hong Kong and argua... 2022-04-30 17:35:35  \n",
            "3  Food and energy price surges worsened by the U... 2022-04-30 17:08:03  \n",
            "4  President Joe Biden is considering forgiving a... 2022-04-30 16:28:48  \n",
            "5  Inflation, lingering supply chain disruptions ... 2022-04-30 16:08:06  \n",
            "6  Few places in the U.S. have felt the sting of ... 2022-04-30 16:07:00  \n",
            "7  Warren Buffett ’s Berkshire Hathaway pulled ba... 2022-04-30 15:36:23  \n",
            "8  The EU seeks a ban on Russian oil by, with res... 2022-04-30 15:30:01  \n",
            "9  Mexico 's fastest inflation in may result in t... 2022-04-30 15:09:05  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8357a8f4-ec16-4150-ade6-87722b597051\", \"economics_Filtered_TW.csv\", 362528)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Youtube API**"
      ],
      "metadata": {
        "id": "985icRedVE_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Referencia: https://stackoverflow.com/questions/63608189/scraping-youtube-comments-using-selenium-and-google-colab-is-slow\n",
        "import sys\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
        "from selenium import webdriver\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "wd = webdriver.Chrome('chromedriver',options=chrome_options)\n",
        "from selenium.webdriver import Chrome\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "import time\n",
        "\n",
        "def scrapecomments(url):\n",
        "  wd.get(url)\n",
        "  tic = time.perf_counter()\n",
        "  wait = WebDriverWait(wd,1)\n",
        "  #wd.get(url)\n",
        "  data1=[]\n",
        "  data2=[]\n",
        "  data3=[]\n",
        "  for item in range(200): \n",
        "          wait.until(EC.visibility_of_element_located((By.TAG_NAME,                \"body\"))).send_keys(Keys.END)\n",
        "          #time.sleep(15)\n",
        "  for author in wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"#author-text\"))):\n",
        "    if len(data1) == 1000:\n",
        "      break\n",
        "    else:\n",
        "      data1.append(author.text)\n",
        "  for comment in wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"#content-text\"))):\n",
        "          data2.append(comment.text)\n",
        "  for likes in wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"#vote-count-middle\"))):\n",
        "          data3.append(likes.text)\n",
        "\n",
        "  def merge(list1, list2, list3):\n",
        "    merged_list = [(list1[i], list2[i], list3[i]) for i in range(0, len(list1))] \n",
        "    return merged_list\n",
        "  \n",
        "  alldata = merge(data1,data2,data3)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
        "  comments = pd.DataFrame(alldata,columns=['user_id','comment','likes'])\n",
        "  comments['rank'] = comments.reset_index().index +1\n",
        "  channel_name = wd.find_element_by_id('channel-name').text\n",
        "  comments['source'] = channel_name\n",
        "  toc = time.perf_counter()\n",
        "  print(f\"Completed scraping {len(data1)} comments in {toc - tic:0.4f} seconds from YouTube {channel_name} channel.\")\n",
        "  return comments\n",
        "\n",
        "url = 'https://www.youtube.com/watch?v=tH2tKigOPBU&ab_channel=MarkRober'\n",
        "df_comments = scrapecomments(url)"
      ],
      "metadata": {
        "id": "FdHpw7vfVEMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing Youtube output"
      ],
      "metadata": {
        "id": "H_K7ciHtVJQT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_comments['Filtered'] = df_comments['comment'].apply(filter)\n",
        "filtered_comments = filtered_tweets = df_twitter[['Filtered']]\n",
        "\n",
        "#Generating the .csv\n",
        "path5 = 'youtube' + '_YT.csv'\n",
        "df_comments.to_csv(path5)\n",
        "files.download(path5)\n",
        "\n",
        "#Generating the .csv for only the filtered posts for topic modeling\n",
        "from google.colab import files\n",
        "path6 = 'youtube' + '_Filtered_YT.csv'\n",
        "filtered_comments .to_csv(path6)\n",
        "files.download(path6)"
      ],
      "metadata": {
        "id": "bg9xig8SVNtB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "outputId": "ebeb92d5-ba9a-4840-8b83-01e4914f953f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           user_id                                            comment likes  \\\n",
              "0                   TOUCHDOWN CONFIRMED!!  WE ARE SAFE ON MARS!  C...   34K   \n",
              "1                      Thanks for spreading the word!! It's go time 😎   29K   \n",
              "2       LordEmor23  My dad helped make the battery for the rover a...  1.3K   \n",
              "3      Toronto Guy  Never realized how big the rovers were until p...  1.7K   \n",
              "4     Shiza Soomro  Bro this man never fails to make me emotional ...   266   \n",
              "..             ...                                                ...   ...   \n",
              "995  General Usage   Is “Mars Rover” just “Mark Rober” mispronounced?     2   \n",
              "996      Jacek-Jan  A Schrodinger Mars rover...\\nIt would be terri...         \n",
              "997       BLIZZARD                       This guy smarter then Elbert         \n",
              "998    Cooper Keel   Touchdown confirmed perseverance is safe on mars   117   \n",
              "999    HHH Horizon  The powder that cleans water in one of your vi...         \n",
              "\n",
              "     rank      source                                     Clean Comments  \n",
              "0       1  Mark Rober  TOUCHDOWN CONFIRMED!!   WE ARE SAFE ON MARS!  ...  \n",
              "1       2  Mark Rober      Thanks for spreading the word!! It 's go time  \n",
              "2       3  Mark Rober  My dad helped make the battery for the rover a...  \n",
              "3       4  Mark Rober  Never realized how big the rovers were until p...  \n",
              "4       5  Mark Rober  Bro this man never fails to make me emotional ...  \n",
              "..    ...         ...                                                ...  \n",
              "995   996  Mark Rober   Is“ Mars Rover” just“ Mark Rober” mispronounced?  \n",
              "996   997  Mark Rober  A Schrodinger Mars rover... \\n It would be ter...  \n",
              "997   998  Mark Rober                       This guy smarter then Elbert  \n",
              "998   999  Mark Rober   Touchdown confirmed perseverance is safe on mars  \n",
              "999  1000  Mark Rober  The powder that cleans water in one of your vi...  \n",
              "\n",
              "[1000 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1235a980-b7d0-4664-af29-52c75f82e68d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>comment</th>\n",
              "      <th>likes</th>\n",
              "      <th>rank</th>\n",
              "      <th>source</th>\n",
              "      <th>Clean Comments</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td></td>\n",
              "      <td>TOUCHDOWN CONFIRMED!!  WE ARE SAFE ON MARS!  C...</td>\n",
              "      <td>34K</td>\n",
              "      <td>1</td>\n",
              "      <td>Mark Rober</td>\n",
              "      <td>TOUCHDOWN CONFIRMED!!   WE ARE SAFE ON MARS!  ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td></td>\n",
              "      <td>Thanks for spreading the word!! It's go time 😎</td>\n",
              "      <td>29K</td>\n",
              "      <td>2</td>\n",
              "      <td>Mark Rober</td>\n",
              "      <td>Thanks for spreading the word!! It 's go time</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LordEmor23</td>\n",
              "      <td>My dad helped make the battery for the rover a...</td>\n",
              "      <td>1.3K</td>\n",
              "      <td>3</td>\n",
              "      <td>Mark Rober</td>\n",
              "      <td>My dad helped make the battery for the rover a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Toronto Guy</td>\n",
              "      <td>Never realized how big the rovers were until p...</td>\n",
              "      <td>1.7K</td>\n",
              "      <td>4</td>\n",
              "      <td>Mark Rober</td>\n",
              "      <td>Never realized how big the rovers were until p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Shiza Soomro</td>\n",
              "      <td>Bro this man never fails to make me emotional ...</td>\n",
              "      <td>266</td>\n",
              "      <td>5</td>\n",
              "      <td>Mark Rober</td>\n",
              "      <td>Bro this man never fails to make me emotional ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>General Usage</td>\n",
              "      <td>Is “Mars Rover” just “Mark Rober” mispronounced?</td>\n",
              "      <td>2</td>\n",
              "      <td>996</td>\n",
              "      <td>Mark Rober</td>\n",
              "      <td>Is“ Mars Rover” just“ Mark Rober” mispronounced?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>Jacek-Jan</td>\n",
              "      <td>A Schrodinger Mars rover...\\nIt would be terri...</td>\n",
              "      <td></td>\n",
              "      <td>997</td>\n",
              "      <td>Mark Rober</td>\n",
              "      <td>A Schrodinger Mars rover... \\n It would be ter...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>BLIZZARD</td>\n",
              "      <td>This guy smarter then Elbert</td>\n",
              "      <td></td>\n",
              "      <td>998</td>\n",
              "      <td>Mark Rober</td>\n",
              "      <td>This guy smarter then Elbert</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>Cooper Keel</td>\n",
              "      <td>Touchdown confirmed perseverance is safe on mars</td>\n",
              "      <td>117</td>\n",
              "      <td>999</td>\n",
              "      <td>Mark Rober</td>\n",
              "      <td>Touchdown confirmed perseverance is safe on mars</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>HHH Horizon</td>\n",
              "      <td>The powder that cleans water in one of your vi...</td>\n",
              "      <td></td>\n",
              "      <td>1000</td>\n",
              "      <td>Mark Rober</td>\n",
              "      <td>The powder that cleans water in one of your vi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1235a980-b7d0-4664-af29-52c75f82e68d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1235a980-b7d0-4664-af29-52c75f82e68d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1235a980-b7d0-4664-af29-52c75f82e68d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}